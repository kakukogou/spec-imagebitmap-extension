<!DOCTYPE html>
<html>
  <head>
    <title>ImageBitmap Extensions</title>
    <meta charset='utf-8'>
    <script src='https://www.w3.org/Tools/respec/respec-w3c-common'
            async class='remove'></script>
    <script class='remove'>
      var respecConfig = {
          // specification status (e.g. WD, LCWD, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "ED",

          // the specification's short name, as in http://www.w3.org/TR/short-name/
          // shortName:            "imagebitmap-extension",

          // if your specification has a subtitle that goes below the main
          // formal title, define it here
          // subtitle   :  "an excellent document",

          // if you wish the publication date to be other than the last modification, set this
          // publishDate:  "2009-08-06",

          // if the specification's copyright date is a range of years, specify
          // the start date here:
          // copyrightStart: "2005"

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "http://kakukogou.github.io/spec-imagebitmap-extension",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2009-08-05",

          // editors, add as many as you like
          // only "name" is required
          editors:  [
              {
                name:       "Tzuhao Kuo",
                company:    "Mozilla",
                companyURL: "http://www.mozilla.com/"
              },
              {
                name:       "Chiahung Tai",
                company:    "Mozilla",
                companyURL: "http://www.mozilla.com/"
              },
              {
                name:       "Robert O'Callahan",
                company:    "Mozilla",
                companyURL: "http://www.mozilla.com/"
              }
          ],

          // name of the WG
          wg:           "In Charge Of This Document Working Group",

          // URI of the public WG page
          wgURI:        "http://example.org/really-cool-wg",

          // name (without the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "spec-writers-anonymous",

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "",
          // !!!! IMPORTANT !!!! MAKE THE ABOVE BLINK IN YOUR HEAD
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This specification extends the <a><code>ImageBitmap interface</code></a>
        to allow JavaScript developers to read the underlying data out and set
        an external data into an <a><code>ImageBitmap</code></a> in a set of
        supported <a>ImageFormat</a>s.
      </p>
      <p>

      </p>
    </section>

    <section id='sotd'>
      <p>
        <strong>This document is not complete and is subject to change. Early
        experimentations are encouraged to allow the Media Capture Task Force
        to evolve the specification based on technical discussions within the
        Task Force, implementation experience gained from early
        implementations, and feedback from other groups and
        individuals.</strong>
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
        The <a><code>ImageBitmap interface</code></a> is originally designed as
        a pure opaque handler to an image data buffer inside a browser so that
        how it stores the buffer is uknown to users and optimized to platforms.
      </p>
      <p>
        Currently, the <em>Media Capture Stream with Video Worker</em>
        specification [<a>mediacapture-worker</a>] proposes a video processing
        framework on the web platform. It provides web applications a way to
        hook a processing script (which is ran in a <a>VideoWorker</a>) to a
        <code>MediaStreamTrack</code> with video data so that each frame will
        be processed accordingly. If a <a>VideoWorker</a> is successfully hooked
        to a track, then for each video frame of the track, the framework will
        post a <a>VideoProcessEvent</a> to the <a>VideoWorker</a>.
        A <a>VideoProcessEvent</a> has an <code>inputImageBitmap</code>
        property and an <code>outputImageBitmap</code> property so that
        JavaScript developers could read the raw image data of the current video
        frame out from the <code>inputImageBitmap</code>, then after some
        processing, write the processed image data back into the
        <code>outputImageBitmap</code> which is handled by the framework thereafter.
        This specification is meant to extend the <a>ImageBitmap interface</a>
        with new APIs to read data from and write data back into an
        <code>ImageBitmap</code>.
      </p>
      <p>
        The <em>Media Capture Stream with Video Worker</em> specification
        [<a>mediacapture-worker</a>] chooses <a><code>ImageBitmap</code></a>
        (instead of <code>ImageData</code>) as the container of video frames
        because the decoded video frame data might exist in either CPU or GPU
        memory which perfectly matches the nature of
        <a><code>ImageBitmap</code></a> as an opaque handler.
      </p>
      <p>
        Considering how would developers process video frames, there are two possible
        ways, via JavaScript(/asm.js) or WebGL.
        <ol>
          <li>
            If developers use WebGL, then treating an ImageBitmap as an opaque
            container, passing it into the WebGL context and the browser will
            handle how to upload the raw image data into the GPU memory.
            Possiblely, the data is already in the GPU memory so that no further
            operation is needed through.
          </li>
          <li>
            If developers use JavaScript(/asm.js) to process the frames, then
            new APIs to access the raw data inside an ImageBitmp are needed
            since the current <a><code>ImageBitmap interface</code></a> provides
            no way for developers to do so.
          </li>
        </ol>
      </p>
      <p>
        In this specification, the original <a>ImageBitmap interface</a> is extended
        with four methods to let developers read data from and write data into an
        <a>ImageBitmap</a> in a set of supported <a>ImageFormat</a>s.
        Also, two interfaces <a>ImageFormatPixelLayout</a> and <a>ChannelPixelLayout</a>
        are proposed to work with the extend <a>ImageBitmap</a> methods to describe
        how the accessed image data is arranged in memory.
      </p>
    </section>

    <section>
      <h2>
        Dependencies
      </h2>
      <p>
        The <code><a href=
        "http://www.w3.org/TR/html51/webappapis.html#images">
        <dfn>ImageBitmap interface</dfn></a></code> this specification extends
        are defined in [[!HTML51]].
      </p>
      <p>
        The <em>Media Capture Stream with Video Worker</em> specificaton proposes a video
        processing framework on the web platform.
        [<a href="http://chiahungtai.github.io/mediacapture-worker/">
        <dfn>mediacapture-worker</dfn></a>]
      </p>
      <p>
        The <code><a href=
        "http://chiahungtai.github.io/mediacapture-worker/#videoworker-interface">
        <dfn>VideoWorker</dfn></a></code> is defined in [<a>mediacapture-worker</a>].
      </p>
      <p>
        The <code><a href=
        "http://chiahungtai.github.io/mediacapture-worker/#videoprocessevent-interface">
        <dfn>VideoProcessEvent</dfn></a></code> is defined in [<a>mediacapture-worker</a>].
      </p>
    </section>

    <section>
      <h2>Image format</h2>
      <p>
        An image or a video frame is conceptually a two-dimentional array of data and each element in the array is called a <strong>pixel</strong>.
        However, the pixels are usually stored in a one-dimentional array and could be arranged in a variety of <a>ImageFormat</a>s.
        Developers need to know how the pixels are formatted so that they are able to process it.

        An <a>ImageFormat</a> describes how pixels in an image are arranged and all pixels in one single image are arranged in the same way.
        A single pixel has at least one, but usually multiple <strong>pixel value</strong>s.
        The range of a pixel value varies, which means different <a>ImageFormat</a>s use different <strong>data type</strong>s to store a single pixel value.
        The most popular data type is 8-bit unsigned interger whose range is from 0 to 255, others could be 16-bit interger or 32-bit folating points and so forth.
        The number of pixle values of a single pixel is called the number of <strong>channels</strong> of the <a>ImageFormat</a>.
        Multiple pixel valuse of a pixel are used together to describe the captured property which could be color or depth information.
        For example, if the data is a color image in RGB color space, then it is a three-channel <a>ImageFormat</a> and a pixel is described by R, G and B three pixel values with range from 0 to 255.
        Another example, if the data is a gray image, then it is a single-channel <a>ImageFormat</a> with 8-bit unsigned interger data type and the pixel value describes the gray scale.
        For depth data, it is a single channel <a>ImageFormat</a> too, but the data type is 16-bit unsigned interger and the pixel value is the depth level.

        For those <a>ImageFormat</a>s whose pixel contain multiple pixel values, the pixel values might be arranged in a planar way or interleaving way:
        <ol>
          <li>
            <strong>Planar pixel layout</strong>: each channel has its pixel values stored consecutively in
            separated buffers (a.k.a. planes) and then all channel buffers are stored
            consecutively in memory.
            (Ex: RRRRRR......GGGGGG......BBBBBB......)
          </li>
          <li>
            <strong>Interleaving pixel layout</strong>: each pixel has its pixel values from all channels
            stored together and interleaves all channels.
            (Ex: RGBRGBRGBRGBRGB......)
          </li>
        </ol>
        <div class="note">
          <p>
            <a>ImageFormat</a>s belong to the same color space might have different pixel layouts.
          </p>
        </div>
      </p>
    </section>

    <section>
      <h2>Components</h2>

      <section>
        <h2>ImageFormat</h2>
        <p>
          An enumeration <a>ImageFormat</a> defines a list of image formats
          which are exposed to users. The extend APIs of <a>ImageBitmap</a> use
          this enumeration to negotiate the format while accessing the
          underlying data of <a>ImageBitmap</a> and writing back.
        </p>
        <div class="note">
          <p>
            We need to elaborate this list for standardization.
          </p>
        </div>
        <dl id="enum-basic" class="idl" title="enum ImageFormat">
          <dt>RGBA32</dt>
          <dd>
            <p>Channel order: R, G, B, A</p>
            <p>Channel size: full rgba-chennels</p>
            <p>Pixel layout: interleaving rgba-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>BGRA32</dt>
          <dd>
            <p>Channel order: B, G, R, A</p>
            <p>Channel size: full bgra-channels</p>
            <p>Pixel layout: interleaving bgra-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>RGB24</dt>
          <dd>
            <p>Channel order: R, G, B</p>
            <p>Channel size: full rgb-channels</p>
            <p>Pixel layout: interleaving rgb-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>BGR24</dt>
          <dd>
            <p>Channel order: B, G, R</p>
            <p>Channel size: full bgr-channels</p>
            <p>Pixel layout: interleaving bgr-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>GRAY8</dt>
          <dd>
            <p>Channel order: GRAY</p>
            <p>Channel size: full gray-channel</p>
            <p>Pixel layout: planar gray-channel</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>YUV444P</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full yuv-channels</p>
            <p>Pixel layout: planar yuv-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>YUV422P</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full y-channel, half uv-channels</p>
            <p>Pixel layout: planar yuv-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>YUV420P</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full y-channel, quarter uv-channels</p>
            <p>Pixel layout: planar yuv-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>YUV420SP_NV12</dt>
          <dd>
            <p>Channel order: Y, U, V</p>
            <p>Channel size: full y-channel, quarter uv-channels</p>
            <p>Pixel layout: planar y-channel, interleaving uv-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>YUV420SP_NV21</dt>
          <dd>
            <p>Channel order: Y, V, U</p>
            <p>Channel size: full y-channel, quarter uv-channels</p>
            <p>Pixel layout: planar y-channel, interleaving vu-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>HSV</dt>
          <dd>
            <p>Channel order: H, S, V</p>
            <p>Channel size: full hsv-channels</p>
            <p>Pixel layout: interleaving hsv-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>Lab</dt>
          <dd>
            <p>Channel order: l, a, b</p>
            <p>Channel size: full lab-channels</p>
            <p>Pixel layout: interleaving lab-channels</p>
            <p>Data type: 8-bit unsigned integer</p>
          </dd>
          <dt>DEPTH</dt>
          <dd>
            <p>Channel order: DEPTH</p>
            <p>Channel size: full depth-channel</p>
            <p>Pixel layout: planar depth-channel</p>
            <p>Data type: 16-bit unsigned integer</p>
          </dd>
        </dl>
      </section>

      <section>
        <h2>PixelLayout</h2>
        <p>
          Two interfaces, <a>ImageFormatPixelLayout</a> and
          <a>ChannelPixelLayout</a>, help together to generalize the variety of
          pixel layouts among image formats.
        </p>
        <p>
          The <a>ImageFormatPixelLayout</a> represents the pixel layout of a
          certain image format and since a image format is composed by at least
          one channel so <a>ImageFormatPixelLayout</a> contains at least one
          <a>ChannelPixelLayout</a>.
        </p>
        <p>
          Although an image or a video frame is a two-dimensional structure, its data
          is usually stored in an one-dimensional array in the raw-major way and the
          <a>ChannelPixelLayout</a> uses the following properties to describe
          how pixel values are arranged in the one dimentional array buffer.
          <ol>
            <li>
              <em>offset</em>: where is each channel's data starts from.
              (Relative to the beginning of the video data one-dimension array.)
            </li>
            <li>
              <em>width</em> and <em>height</em>:
              how much samples are in each channel.
            </li>
            <li>
              <em>data type</em>: the data type used to store one single pixel value.
            </li>
            <li>
              <em>stride</em>: the total bytes of each raw plus the padding bytes of each row.
            </li>
            <li>
              <em>skip</em>: this is used to describe interleaving layout.
              (For planar layout, this property will be zero.)
            </li>
          </ol>
        </p>

        <pre class='example highlight'>
          Example1: RGBA image, width = 620, height = 480, stride = 2560

          chanel_r: offset = 0, width = 620, height = 480, data type = uint8, stride = 2560, skip = 3
          chanel_g: offset = 1, width = 620, height = 480, data type = uint8, stride = 2560, skip = 3
          chanel_b: offset = 2, width = 620, height = 480, data type = uint8, stride = 2560, skip = 3
          chanel_a: offset = 3, width = 620, height = 480, data type = uint8, stride = 2560, skip = 3

                  <---------------------------- stride ---------------------------->
                  <---------------------- width x 4 ---------------------->
          [index] 01234   8   12  16  20  24  28                           2479    2559
                  |||||---|---|---|---|---|---|----------------------------|-------|
          [data]  RGBARGBARGBARGBARGBAR___R___R...                         A%%%%%%%%
          [data]  RGBARGBARGBARGBARGBAR___R___R...                         A%%%%%%%%
          [data]  RGBARGBARGBARGBARGBAR___R___R...                         A%%%%%%%%
                       ^^^
                       r-skip
        </pre>

        <pre class='example highlight'>
          Example2: YUV420P image, width = 620, height = 480, stride = 640

          chanel_y: offset = 0, width = 620, height = 480, stride = 640, skip = 0
          chanel_u: offset = 307200, width = 310, height = 240, data type = uint8, stride = 320, skip = 0
          chanel_v: offset = 384000, width = 310, height = 240, data type = uint8, stride = 320, skip = 0

                  <--------------------------- y-stride --------------------------->
                  <----------------------- y-width ----------------------->
          [index] 012345                                                  619      639
                  ||||||--------------------------------------------------|--------|
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                        Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                        Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                        Y%%%%%%%%%
          [data]  ......
                  <-------- u-stride ---------->
                  <----- u-width ----->
          [index] 307200              307509   307519
                  |-------------------|--------|
          [data]  UUUUUUUUUU...       U%%%%%%%%%
          [data]  UUUUUUUUUU...       U%%%%%%%%%
          [data]  UUUUUUUUUU...       U%%%%%%%%%
          [data]  ......
                  <-------- v-stride ---------->
                  <- --- v-width ----->
          [index] 384000              384309   384319
                  |-------------------|--------|
          [data]  VVVVVVVVVV...       V%%%%%%%%%
          [data]  VVVVVVVVVV...       V%%%%%%%%%
          [data]  VVVVVVVVVV...       V%%%%%%%%%
          [data]  ......
        </pre>

        <pre class='example highlight'>
          Example3: YUV420SP_NV12 image, width = 620, height = 480, stride = 640

          chanel_y: offset = 0, width = 620, height = 480, stride = 640, skip = 0
          chanel_u: offset = 307200, width = 310, height = 240, data type = uint8, stride = 640, skip = 1
          chanel_v: offset = 307201, width = 310, height = 240, data type = uint8, stride = 640, skip = 1

                  <--------------------------- y-stride -------------------------->
                  <----------------------- y-width ---------------------->
          [index] 012345                                                 619      639
                  ||||||-------------------------------------------------|--------|
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                       Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                       Y%%%%%%%%%
          [data]  YYYYYYYYYYYYYYYYYYYYYYYYYYYYY...                       Y%%%%%%%%%
          [data]  ......
                  <--------------------- u-stride / v-stride -------------------->
                  <------------------ u-width + v-width ----------------->
          [index] 307200(u-offset)                                       307819  307839
                  |------------------------------------------------------|-------|
          [index] |307201(v-offset)                                      |307820 |
                  ||-----------------------------------------------------||------|
          [data]  UVUVUVUVUVUVUVUVUVUVUVUVUVUVUV...                      UV%%%%%%%
          [data]  UVUVUVUVUVUVUVUVUVUVUVUVUVUVUV...                      UV%%%%%%%
          [data]  UVUVUVUVUVUVUVUVUVUVUVUVUVUVUV...                      UV%%%%%%%
                   ^            ^
                  u-skip        v-skip
        </pre>

        <pre class='example highlight'>
          Example4: DEPTH image, width = 640, height = 480, stride = 1280

          chanel_d: offset = 0, width = 640, height = 480, data type = uint16, stride = 1280, skip = 0

                  <----------------------- d-stride ---------------------->
                  <----------------------- d-width ----------------------->
          [index] 012345                                                  1280
                  ||||||--------------------------------------------------|
          [data]  DDDDDDDDDDDDDDDDDDDDDDDDDDDDD...                        D
          [data]  DDDDDDDDDDDDDDDDDDDDDDDDDDDDD...                        D
          [data]  DDDDDDDDDDDDDDDDDDDDDDDDDDDDD...                        D
          [data]  ......
        </pre>

        <section>
          <h2>ImageFormatPixelLayout</h2>
          <dl class="idl" title="[Exposed=(Window,Worker)] interface ChannelPixelLayout">
            <dt>
              [Constant]
              readonly attribute unsigned long offset
            </dt>
            <dd>
              <p>
                The beginning position of this channel's data (relative to the given
                ArrayBuffer parameter of the mapDataInto() method.)
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long width
            </dt>
            <dd>
              <p>
                The width of this channel.
                Channels in a image format may have different width.
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long height
            </dt>
            <dd>
              <p>
                The height of this channel.
                Channels in a image format may have different height.
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute DataType dataType
            </dt>
            <dd>
              <p>
                The data type used to store one single pixel value.
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long stride
            </dt>
            <dd>
              <p>
                The stride of this channel.
                The stride is the number of bytes between the beging two consecutive raws in memory.
                The total bytes of each raw plus the padding bytes of each raw.
              </p>
            </dd>

            <dt>
              [Constant]
              readonly attribute unsigned long skip
            </dt>
            <dd>
              <p>
                This is used to describe how much bytes between two adjacent pixel values
                in this channel.
              </p>
              <p>
                Possible values:
                <ul>
                  <li>
                    zero: for planar format.
                  </li>
                  <li>
                    a positive integer: for interleaving format.
                  </li>
                </ul>
              </p>
            </dd>
          </dl>

          <dl id="enum-basic" class="idl" title="enum DataType">
            <dt>uint8</dt>
            <dd>
              8-bit unsigned integer.
            </dd>

            <dt>int8</dt>
            <dd>
              8-bit integer.
            </dd>

            <dt>uint16</dt>
            <dd>
              16-bit unsigned integer.
            </dd>

            <dt>int16</dt>
            <dd>
              16-bit integer.
            </dd>

            <dt>uint32</dt>
            <dd>
              32-bit unsigned integer.
            </dd>

            <dt>int32</dt>
            <dd>
              32-bit integer.
            </dd>

            <dt>float32</dt>
            <dd>
              32-bit IEEE floating point number.
            </dd>

            <dt>float64</dt>
            <dd>
              64-bit IEEE floating point number.
            </dd>

          </dl>
        </section>

        <section>
          <h2>ChannelPixelLayout</h2>
          <dl class="idl" title="[Exposed=(Window,Worker)] interface ImageFormatPixelLayout">
            <dt>
              [Constant, Cached]
              readonly attribute sequence&lt;ChannelPixelLayout&gt; channels
            </dt>
            <dd>
              <p>
                Channel information of this image format.
                Each image format has at least one channel.
              <p>
            </dd>
          </dl>
        </section>
      </section>

      <section>
        <h2>ImageBitmap extensions</h2>
        <dl class="idl" title="[Exposed=(Window,Worker)] partial interface ImageBitmap">
          <dt>
            ImageFormat findOptimalFormat()
          </dt>
          <dd>
            <p>
              Find the best image format for receiving data.
            </p>
            <p>
              @return one of the <code>possibleFormats</code> or the empty
              string if no any format in the list is supported. If the
              <code>possibleFormats</code> is not given, then returns the most
              suitable image format for this ImageBitmap from all supported
              image formats.
            </p>
            <dl class="parameters">
              <dt>optional sequence&lt;ImageFormat&gt; possibleFormats</dt>
              <dd>
                <p>A list of image formats that users can handler.</p>
              </dd>
            </dl>
          </dd>

          <dt>
            [Throws]
            long mappedDataLength()
          </dt>
          <dd>
            <p>
              Calculate the length of mapped data wile the image is represented
              in the given <code>format</code>.
            </p>
            <p>
              Throws if <code>format</code> is not supported.
            </p>
            <p>
              @return the length (in bytes) of image data the represented in the
              given <code>format</code>.
            </p>
            <dl class="parameters">
              <dt>ImageFormat format</dt>
              <dd>
                <p>The format that users want.</p>
              </dd>
            </dl>
          </dd>

          <dt>
            [Throws]
            Promise&lt;ImageFormatPixelLayout&gt; mapDataInto()
            <!-- ImageFormatPixelLayout mapDataInto() -->
          </dt>
          <dd>
            <p>
              Makes a copy of the underlying image data in the given format
              <code>format</code> into the given <code>buffer</code> at offset
              <code>offset</code>, filling at most <code>length</code> bytes and
              returns a <a>ImageFormatPixelLayout</a> object which describes the
              pixel layout.
            </p>
            <p>
              Throws if <code>format</code> is not supported.
            </p>
            <p>
              Each time this method is invoked returns a new
              <a>ImageFormatPixelLayout</a> object.
            </p>
            <p>
              @return a <a>ImageFormatPixelLayout</a> object which describes the
              pixel layout.
            </p>
            <dl class="parameters">
              <dt>ImageFormat format</dt>
              <dd>
                <p>The format that users want.</p>
              </dd>
              <dt>ArrayBuffer buffer</dt>
              <dd>
                <p>A container for receiving the mapped image data.</p>
              </dd>
              <dt>long offset</dt>
              <dd>
                <p>
                  The beginning position of the <code>buffer</code> to place
                  the mapped data.
                </p>
              </dd>
              <dt>long length</dt>
              <dd>
                <p>
                  The length of space in the <code>buffer</code> that could be
                  filled.
                </p>
              </dd>
            </dl>
          </dd>

          <dt>
            [Throws]
            boolean setDataFrom()
          </dt>
          <dd>
            <p>
              Set an external image data into a <code>ImageBitmap</code>.
            </p>
            <dl class="parameters">
              <dt>ImageFormat format</dt>
              <dd>
                <p>The format of the external image data.</p>
              </dd>
              <dt>ArrayBuffer buffer</dt>
              <dd>
                <p>A container of the external image data.</p>
              </dd>
              <dt>long offset</dt>
              <dd>
                <p>
                  The beginning position of the <code>buffer</code> where the
                  external image data is placed.
                </p>
              </dd>
              <dt>long length</dt>
              <dd>
                <p>
                  The length of spaces in the <code>buffer</code> that the
                  external image data is palced.
                </p>
              </dd>
              <dt>ImageFormatPixelLayout layout</dt>
              <dd>
                <p>
                  The pixel layout of the external image data, which describes
                  how the data is arranged in the given <code>buffer</code> as
                  the given <code>format</code>.
                </p>
              </dd>
            </dl>
          </dd>
        </dl>
      </section>

    </section>

    <section class='appendix'>
      <h2>Acknowledgements</h2>
      <p>
        Thanks to Jeff Muizelaar for providing insightful oppinions in the APIs
        design and the experimantal implement.
      </p>
    </section>
  </body>
</html>
